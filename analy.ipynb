{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-08T22:40:40.498754Z",
     "start_time": "2024-10-08T22:40:40.118150Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def load_and_combine_pkl_files(directory_path):\n",
    "    # List to hold all the dataframes\n",
    "    dataframes = []\n",
    "\n",
    "    # Loop through all the files in the specified directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\"45100_45300_new_gradient_conf_new_perturbed_inferenced_df.pkl\"):\n",
    "            # Construct full file path\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            # Load the dataframe from a pkl file\n",
    "            df = pd.read_pickle(file_path)\n",
    "            # Append the dataframe to the list\n",
    "            dataframes.append(df)\n",
    "\n",
    "    # Concatenate all dataframes into one big dataframe\n",
    "    big_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    return big_df\n",
    "\n",
    "\n",
    "# Usage\n",
    "directory_path = '/Users/ximing/Desktop/Explainprompt/step/'\n",
    "big_df = load_and_combine_pkl_files(directory_path)\n",
    "big_df = big_df\n",
    "print(big_df)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                prompt  \\\n",
      "0    is also a testament to the integrity and visio...   \n",
      "1    frankly , it 's kind of insulting , both to me...   \n",
      "2    about growing up that we do n't see often enou...   \n",
      "3    suffers from too much norma rae and not enough...   \n",
      "4    offering next to little insight into its intri...   \n",
      "..                                                 ...   \n",
      "193  in auteil 's less dramatic but equally incisiv...   \n",
      "194  it 's been hyped to be because it plays everyt...   \n",
      "195  a story that puts old-fashioned values under t...   \n",
      "196  the service of a limpid and conventional histo...   \n",
      "197  the movie deals with hot-button issues in a co...   \n",
      "\n",
      "                                           real_output  \\\n",
      "0                     NEGATIVE^.\\n\\nAnswer: ^NEGATIVE^   \n",
      "1                     NEGATIVE^.\\n\\nAnswer: ^NEGATIVE^   \n",
      "2    NEGATIVE^.\\n\\n^NEGATIVE^ I understand. Growing...   \n",
      "3                                           NEGATIVE^.   \n",
      "4                                           NEGATIVE^.   \n",
      "..                                                 ...   \n",
      "193                   NEGATIVE^.\\n\\nAnswer: ^NEGATIVE^   \n",
      "194                   NEGATIVE^.\\n\\nAnswer: ^NEGATIVE^   \n",
      "195                                         NEGATIVE^.   \n",
      "196                                         POSITIVE^.   \n",
      "197                                         POSITIVE^.   \n",
      "\n",
      "                                           token_level  \\\n",
      "0    {'tokens': [{'token': 'is', 'type': 'input', '...   \n",
      "1    {'tokens': [{'token': 'fran', 'type': 'input',...   \n",
      "2    {'tokens': [{'token': 'about', 'type': 'input'...   \n",
      "3    {'tokens': [{'token': 'suff', 'type': 'input',...   \n",
      "4    {'tokens': [{'token': 'offering', 'type': 'inp...   \n",
      "..                                                 ...   \n",
      "193  {'tokens': [{'token': 'in', 'type': 'input', '...   \n",
      "194  {'tokens': [{'token': 'it', 'type': 'input', '...   \n",
      "195  {'tokens': [{'token': 'a', 'type': 'input', 'v...   \n",
      "196  {'tokens': [{'token': 'the', 'type': 'input', ...   \n",
      "197  {'tokens': [{'token': 'the', 'type': 'input', ...   \n",
      "\n",
      "                                            word_level  label  \\\n",
      "0    {'tokens': [{'token': 'is', 'type': 'input', '...      1   \n",
      "1    {'tokens': [{'token': 'frankly', 'type': 'inpu...      0   \n",
      "2    {'tokens': [{'token': 'about', 'type': 'input'...      1   \n",
      "3    {'tokens': [{'token': 'suffers', 'type': 'inpu...      0   \n",
      "4    {'tokens': [{'token': 'offering', 'type': 'inp...      0   \n",
      "..                                                 ...    ...   \n",
      "193  {'tokens': [{'token': 'in', 'type': 'input', '...      1   \n",
      "194  {'tokens': [{'token': 'it', 'type': 'input', '...      0   \n",
      "195  {'tokens': [{'token': 'a', 'type': 'input', 'v...      1   \n",
      "196  {'tokens': [{'token': 'the', 'type': 'input', ...      0   \n",
      "197  {'tokens': [{'token': 'the', 'type': 'input', ...      1   \n",
      "\n",
      "                                       component_level  \\\n",
      "0    ({'instruction': 0.6869505691818736, 'query': ...   \n",
      "1    ({'instruction': 0.6350554476014837, 'query': ...   \n",
      "2    ({'instruction': 0.6409476831245344, 'query': ...   \n",
      "3    ({'instruction': 0.7816545429619639, 'query': ...   \n",
      "4    ({'instruction': 0.8076528685384753, 'query': ...   \n",
      "..                                                 ...   \n",
      "193  ({'instruction': 0.7303164709026397, 'query': ...   \n",
      "194  ({'instruction': 0.6838995848574252, 'query': ...   \n",
      "195  ({'instruction': 0.6994217428622168, 'query': ...   \n",
      "196  ({'instruction': 0.6624836063254568, 'query': ...   \n",
      "197  ({'instruction': 0.7649456650800999, 'query': ...   \n",
      "\n",
      "                                           instruction  \\\n",
      "0    Analyze the sentiment of the previous sentence...   \n",
      "1    Analyze the sentiment of the previous sentence...   \n",
      "2    Analyze the sentiment of the previous sentence...   \n",
      "3    Analyze the sentiment of the previous sentence...   \n",
      "4    Analyze the sentiment of the previous sentence...   \n",
      "..                                                 ...   \n",
      "193  Analyze the sentiment of the previous sentence...   \n",
      "194  Analyze the sentiment of the previous sentence...   \n",
      "195  Analyze the sentiment of the previous sentence...   \n",
      "196  Analyze the sentiment of the previous sentence...   \n",
      "197  Analyze the sentiment of the previous sentence...   \n",
      "\n",
      "                                                 query  \\\n",
      "0    is also a testament to the integrity and visio...   \n",
      "1    frankly , it 's kind of insulting , both to me...   \n",
      "2    about growing up that we do n't see often enou...   \n",
      "3    suffers from too much norma rae and not enough...   \n",
      "4    offering next to little insight into its intri...   \n",
      "..                                                 ...   \n",
      "193  in auteil 's less dramatic but equally incisiv...   \n",
      "194  it 's been hyped to be because it plays everyt...   \n",
      "195  a story that puts old-fashioned values under t...   \n",
      "196  the service of a limpid and conventional histo...   \n",
      "197  the movie deals with hot-button issues in a co...   \n",
      "\n",
      "                                       component_range  instruction_weight  \\\n",
      "0    {'instruction': [12, 13, 14, 15, 16, 17, 18, 1...            0.686951   \n",
      "1    {'instruction': [14, 15, 16, 17, 18, 19, 20, 2...            0.635055   \n",
      "2    {'instruction': [12, 13, 14, 15, 16, 17, 18, 1...            0.640948   \n",
      "3    {'instruction': [11, 12, 13, 14, 15, 16, 17, 1...            0.781655   \n",
      "4    {'instruction': [9, 10, 11, 12, 13, 14, 15, 16...            0.807653   \n",
      "..                                                 ...                 ...   \n",
      "193  {'instruction': [9, 10, 11, 12, 13, 14, 15, 16...            0.730316   \n",
      "194  {'instruction': [12, 13, 14, 15, 16, 17, 18, 1...            0.683900   \n",
      "195  {'instruction': [9, 10, 11, 12, 13, 14, 15, 16...            0.699422   \n",
      "196  {'instruction': [9, 10, 11, 12, 13, 14, 15, 16...            0.662484   \n",
      "197  {'instruction': [10, 11, 12, 13, 14, 15, 16, 1...            0.764946   \n",
      "\n",
      "     ...                      query_token_top_0.25_peturbed  \\\n",
      "0    ...  [{'token': 'is', 'type': 'input', 'value': 0.0...   \n",
      "1    ...  [{'token': 'frankly', 'type': 'input', 'value'...   \n",
      "2    ...  [{'token': 'about', 'type': 'input', 'value': ...   \n",
      "3    ...  [{'token': 'suffers', 'type': 'input', 'value'...   \n",
      "4    ...  [{'token': 'offering', 'type': 'input', 'value...   \n",
      "..   ...                                                ...   \n",
      "193  ...  [{'token': 'in', 'type': 'input', 'value': 0.0...   \n",
      "194  ...  [{'token': 'it', 'type': 'input', 'value': 0.0...   \n",
      "195  ...  [{'token': 'a', 'type': 'input', 'value': 0.00...   \n",
      "196  ...  [{'token': 'the', 'type': 'input', 'value': 0....   \n",
      "197  ...  [{'token': 'the', 'type': 'input', 'value': 0....   \n",
      "\n",
      "                      query_token_bottom_0.25_peturbed  \\\n",
      "0    [{'token': 'is', 'type': 'input', 'value': 0.0...   \n",
      "1    [{'token': 'frankly', 'type': 'input', 'value'...   \n",
      "2    [{'token': 'about', 'type': 'input', 'value': ...   \n",
      "3    [{'token': 'suffers', 'type': 'input', 'value'...   \n",
      "4    [{'token': 'offering', 'type': 'input', 'value...   \n",
      "..                                                 ...   \n",
      "193  [{'token': 'motherwort', 'type': 'input', 'val...   \n",
      "194  [{'token': 'it', 'type': 'input', 'value': 0.0...   \n",
      "195  [{'token': 'sylleptical', 'type': 'input', 'va...   \n",
      "196  [{'token': 'thrombogenic', 'type': 'input', 'v...   \n",
      "197  [{'token': 'the', 'type': 'input', 'value': 0....   \n",
      "\n",
      "                    top_reconstructed_instruction_0.25  \\\n",
      "0    is also a testament to the integrity and visio...   \n",
      "1    frankly , it 's kind of insulting , both to me...   \n",
      "2    about growing up that we do n't see often enou...   \n",
      "3    suffers from too much norma rae and not enough...   \n",
      "4    offering next to little insight into its intri...   \n",
      "..                                                 ...   \n",
      "193  in auteil 's less dramatic but equally incisiv...   \n",
      "194  it 's been hyped to be because it plays everyt...   \n",
      "195  a story that puts old-fashioned values under t...   \n",
      "196  the service of a limpid and conventional histo...   \n",
      "197  the movie deals with hot-button issues in a co...   \n",
      "\n",
      "                          top_reconstructed_query_0.25  \\\n",
      "0    is also a Lyonetia to the murza and semicordat...   \n",
      "1    frankly , it squeeze kind of semitangent , bot...   \n",
      "2    about growing up that we do bogieman see Orige...   \n",
      "3    suffers from too much stringing rae and not en...   \n",
      "4    offering next to little gatemaker into its pre...   \n",
      "..                                                 ...   \n",
      "193  in auteil 's less dramatic but aggroup Geospiz...   \n",
      "194  it 's been hyped to be because it rumless allo...   \n",
      "195  a story that puts unconfiscated values under t...   \n",
      "196  the service of a limpid and conventional hagga...   \n",
      "197  the movie deals with pliothermic issues in a s...   \n",
      "\n",
      "                 bottom_reconstructed_instruction_0.25  \\\n",
      "0    is also a testament to the integrity and visio...   \n",
      "1    frankly , it 's kind of insulting , both to me...   \n",
      "2    about growing up that we do n't see often enou...   \n",
      "3    suffers from too much norma rae and not enough...   \n",
      "4    offering next to little insight into its intri...   \n",
      "..                                                 ...   \n",
      "193  in auteil 's less dramatic but equally incisiv...   \n",
      "194  it 's been hyped to be because it plays everyt...   \n",
      "195  a story that puts old-fashioned values under t...   \n",
      "196  the service of a limpid and conventional histo...   \n",
      "197  the movie deals with hot-button issues in a co...   \n",
      "\n",
      "                       bottom_reconstructed_query_0.25  \\\n",
      "0    is also a testament to the integrity recopper ...   \n",
      "1    frankly tocherless delineation 's kind of insu...   \n",
      "2    about Echinorhinidae underaccident humerodigit...   \n",
      "3    suffers from schimmel much norma rae and Zambe...   \n",
      "4    offering next to little insight unintrusted gl...   \n",
      "..                                                 ...   \n",
      "193  motherwort auteil 's less dramatic hemiletharg...   \n",
      "194  it 's berylloid hyped to amphibrach because an...   \n",
      "195  sylleptical story lysimeter puts old-fashioned...   \n",
      "196  thrombogenic service unbrotherly a limpid and ...   \n",
      "197  the movie deals mignonette hot-button issues p...   \n",
      "\n",
      "             top_reconstructed_instruction_0.25_result  \\\n",
      "0    ^\\n\\nThe band Mikasuki is a testament to the i...   \n",
      "1    ^; \\n\\nAnswer:\\n\\nI understand your concern, a...   \n",
      "2    ^.\\n\\nComment: 00:00:00 I think it's great tha...   \n",
      "3                                        ^\\n\\n\\n\\n\\n\\n   \n",
      "4    ^\\n\\nSulphoborite Akiyenik is a rare and fasci...   \n",
      "..                                                 ...   \n",
      "193  CORRECT^.\\n\\nIn this passage, the author is di...   \n",
      "194  NEGATIVE^.\\n\\nThe game is a fun and engaging e...   \n",
      "195  &*()_$#@! I apologize, but I'm a large languag...   \n",
      "196  ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ...   \n",
      "197  &*()_$#@! I don't think that's an appropriate ...   \n",
      "\n",
      "                   top_reconstructed_query_0.25_result  \\\n",
      "0    NEGATIVE^.\\n\\nI apologize, but I cannot comply...   \n",
      "1                     NEGATIVE^.\\n\\nAnswer: ^NEGATIVE^   \n",
      "2                                           NEGATIVE^.   \n",
      "3                                           NEGATIVE^.   \n",
      "4    NEGATIVE^.\\n\\nI apologize, but I'm a large lan...   \n",
      "..                                                 ...   \n",
      "193                           NEGATIVE^.\\n\\n^NEGATIVE^   \n",
      "194  NEGATIVE^.\\n\\nIt's been hyped to be because it...   \n",
      "195                                         POSITIVE^.   \n",
      "196  NEGATIVE^.\\n\\nThe sentiment of the previous se...   \n",
      "197                                         NEGATIVE^.   \n",
      "\n",
      "          bottom_reconstructed_instruction_0.25_result  \\\n",
      "0    POSITIVE^.\\n\\nThe song is a testament to the i...   \n",
      "1    ter ^POSITIVE^.\\n\\nAnswer:\\nThe sentiment of t...   \n",
      "2    NEGATIVE^.\\n\\nThe word \"oaklike\" in the senten...   \n",
      "3    POSITIVE^.\\n\\nAnswer:\\nThe sentiment of the pr...   \n",
      "4    POSITIVE^.\\n\\nAnswer:\\n\\nThe sentiment of the ...   \n",
      "..                                                 ...   \n",
      "193                                                ^^    \n",
      "194  NEGATIVE^.\\n\\nThe sentiment of the sentence \"I...   \n",
      "195  POSITIVE^.\\n\\nThe story is a heartwarming tale...   \n",
      "196  POSITIVE^ if the sentence expresses a positive...   \n",
      "197  POSITIVE^.\\n\\nThe movie deals with hot-button ...   \n",
      "\n",
      "                bottom_reconstructed_query_0.25_result  \n",
      "0    NEGATIVE^.\\n\\nThe sentiment of the previous se...  \n",
      "1    NEGATIVE^.\\n\\nAnswer: NEGATIVE. The sentence i...  \n",
      "2                     NEGATIVE^.\\n\\nAnswer: ^NEGATIVE^  \n",
      "3    NEGATIVE^.\\n\\nI apologize, but the sentence yo...  \n",
      "4    NEGATIVE^.\\n\\nI apologize, but I don't think t...  \n",
      "..                                                 ...  \n",
      "193                           NEGATIVE^.\\n\\n^NEGATIVE^  \n",
      "194  NEGATIVE^.\\n\\nThe sentiment of the previous se...  \n",
      "195                                         NEGATIVE^.  \n",
      "196  NEGATIVE^.\\n\\n^NEGATIVE^ The sentiment of the ...  \n",
      "197  NEGATIVE^.\\n\\nThe movie deals with hot-button ...  \n",
      "\n",
      "[198 rows x 29 columns]\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T22:40:44.873864Z",
     "start_time": "2024-10-08T22:40:44.868090Z"
    }
   },
   "cell_type": "code",
   "source": "print(big_df.columns)",
   "id": "245a45e8399d08b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['prompt', 'real_output', 'token_level', 'word_level', 'label',\n",
      "       'component_level', 'instruction', 'query', 'component_range',\n",
      "       'instruction_weight', 'query_weight', 'exec_time', 'gpu_memory_usage',\n",
      "       'instructions_tokens', 'query_tokens', 'max_normalized_value',\n",
      "       'max_token', 'instruction_token_top_0.25_peturbed',\n",
      "       'instruction_token_bottom_0.25_peturbed',\n",
      "       'query_token_top_0.25_peturbed', 'query_token_bottom_0.25_peturbed',\n",
      "       'top_reconstructed_instruction_0.25', 'top_reconstructed_query_0.25',\n",
      "       'bottom_reconstructed_instruction_0.25',\n",
      "       'bottom_reconstructed_query_0.25',\n",
      "       'top_reconstructed_instruction_0.25_result',\n",
      "       'top_reconstructed_query_0.25_result',\n",
      "       'bottom_reconstructed_instruction_0.25_result',\n",
      "       'bottom_reconstructed_query_0.25_result'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T22:40:46.970212Z",
     "start_time": "2024-10-08T22:40:46.949526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "big_df['sentiment'] = big_df['real_output'].apply(lambda x: 1 if 'POS' in x else (0 if 'NEG' in x else -1))\n",
    "big_df['sentiment_top_reconstructed_instruction'] = big_df['top_reconstructed_instruction_0.25_result'].apply(lambda x: 1 if 'POS' in x else (0 if 'NEG' in x else -1))\n",
    "big_df['sentiment_top_reconstructed_query'] = big_df['top_reconstructed_query_0.25_result'].apply(lambda x: 1 if 'POS' in x else (0 if 'NEG' in x else -1))\n",
    "big_df['sentiment_bottom_reconstructed_instruction'] = big_df['bottom_reconstructed_instruction_0.25_result'].apply(lambda x: 1 if 'POS' in x else (0 if 'NEG' in x else -1))\n",
    "big_df['sentiment_bottom_reconstructed_query'] = big_df['bottom_reconstructed_query_0.25_result'].apply(lambda x: 1 if 'POS' in x else (0 if 'NEG' in x else -1))\n"
   ],
   "id": "c6e996bf6ea8e2a9",
   "outputs": [],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T22:40:49.045753Z",
     "start_time": "2024-10-08T22:40:49.034520Z"
    }
   },
   "cell_type": "code",
   "source": "print(big_df['sentiment_bottom_reconstructed_query'])",
   "id": "2dc5d355942bca13",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "193    0\n",
      "194    0\n",
      "195    0\n",
      "196    0\n",
      "197    0\n",
      "Name: sentiment_bottom_reconstructed_query, Length: 198, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T22:40:50.832084Z",
     "start_time": "2024-10-08T22:40:50.824532Z"
    }
   },
   "cell_type": "code",
   "source": [
    "differences = big_df['sentiment'] != big_df['sentiment_top_reconstructed_instruction']\n",
    "print(differences.sum() / len(differences))"
   ],
   "id": "6a3f89be33a9cb2d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9141414141414141\n"
     ]
    }
   ],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T22:40:52.360661Z",
     "start_time": "2024-10-08T22:40:52.354924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "differences = big_df['sentiment'] != big_df['sentiment_top_reconstructed_query']\n",
    "print(differences.sum() / len(differences))"
   ],
   "id": "bf3c6af4703d88a6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25252525252525254\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T22:41:28.587761Z",
     "start_time": "2024-10-08T22:41:28.580289Z"
    }
   },
   "cell_type": "code",
   "source": [
    "differences = big_df['sentiment'] != big_df['sentiment_bottom_reconstructed_instruction']\n",
    "print(differences.sum() / len(differences))"
   ],
   "id": "27f35643d79dbc33",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5757575757575758\n"
     ]
    }
   ],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T22:41:30.917514Z",
     "start_time": "2024-10-08T22:41:30.910674Z"
    }
   },
   "cell_type": "code",
   "source": [
    "differences = big_df['sentiment'] != big_df['sentiment_bottom_reconstructed_query']\n",
    "print(differences.sum() / len(differences))"
   ],
   "id": "49383f11e793d85c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1717171717171717\n"
     ]
    }
   ],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T22:41:15.577651Z",
     "start_time": "2024-10-08T22:41:15.452828Z"
    }
   },
   "cell_type": "code",
   "source": "expanded_df = pd.DataFrame([word for sublist in big_df['instructions_tokens'] for word in sublist])\n",
   "id": "391e96cb3fd22eee",
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T14:01:29.183622Z",
     "start_time": "2024-09-26T14:01:29.165521Z"
    }
   },
   "cell_type": "code",
   "source": [
    "grouped_stats = expanded_df.groupby('token').agg({\n",
    "    'value': ['sum', 'mean']  # 计算总和和均值\n",
    "}).reset_index()\n",
    "grouped_stats.columns = ['token', 'total_value', 'average_value']  # 重新命名列以便阅读\n",
    "print(grouped_stats)"
   ],
   "id": "c3144def9ae2039",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     token  total_value  average_value\n",
      "0  Respond     7.035245       0.071788\n",
      "1        a     6.954704       0.070966\n",
      "2     form     6.981214       0.071237\n",
      "3       in     6.979714       0.071222\n",
      "4     long     6.955979       0.070979\n",
      "5       of     6.989855       0.071325\n",
      "6    story     6.931501       0.070730\n",
      "7      the     6.994080       0.071368\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3c623e756b5c12ad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b27e41a92733d7c6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "5658b3c1028cc4b2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "discretize ",
   "id": "4548d244dae7be26"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T13:59:00.407256Z",
     "start_time": "2024-09-26T13:59:00.382727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "grouped_stats = expanded_df.groupby('token').agg({\n",
    "    'value': ['sum', 'mean']  # 计算总和和均值\n",
    "}).reset_index()\n",
    "grouped_stats.columns = ['token', 'total_value', 'average_value']  # 重新命名列以便阅读\n",
    "print(grouped_stats)"
   ],
   "id": "b9b9a554ae48ed4f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     token  total_value  average_value\n",
      "0  Respond     6.650957       0.067867\n",
      "1        a     6.684485       0.068209\n",
      "2     form     6.512113       0.066450\n",
      "3       in     6.794886       0.069336\n",
      "4     long     7.163081       0.073093\n",
      "5       of     6.620741       0.067559\n",
      "6    story     7.846718       0.080069\n",
      "7      the     6.574434       0.067086\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "5e63fbd4a8c0456b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "simliarity ",
   "id": "3ef8da2fbddb9841"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T13:55:26.252261Z",
     "start_time": "2024-09-26T13:55:26.072339Z"
    }
   },
   "cell_type": "code",
   "source": [
    "grouped_stats = expanded_df.groupby('token').agg({\n",
    "    'value': ['sum', 'mean']  # 计算总和和均值\n",
    "}).reset_index()\n",
    "grouped_stats.columns = ['token', 'total_value', 'average_value']  # 重新命名列以便阅读\n",
    "print(grouped_stats)"
   ],
   "id": "5c1a9cb227357251",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     token  total_value  average_value\n",
      "0  Respond     4.941783       0.050426\n",
      "1        a     5.138980       0.052439\n",
      "2     form     5.004630       0.051068\n",
      "3       in     5.109278       0.052135\n",
      "4     long     5.712436       0.058290\n",
      "5       of     5.075337       0.051789\n",
      "6    story     7.830939       0.079908\n",
      "7      the     4.838620       0.049374\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "251a5ae7efb58992"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "24b1283581bfa61c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "76667b9c0bb511a1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ffeb71503b0941bf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "31b1ed64c19581f3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "dcdb33f4d7553897"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7703a7e1cba43b7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(big_df.iloc[4]['word_level'])",
   "id": "1f40caaa06320c4e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(big_df['bottom_reconstructed_query_0.2_result'][:20])\n",
   "id": "9235a358387f836e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T14:00:39.832484Z",
     "start_time": "2024-09-24T17:52:08.148851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "differences = big_df['real_output'] != big_df['bottom_reconstructed_query_0.2_result']\n",
    "print(differences.sum()/len(differences))"
   ],
   "id": "864ecdc676891e34",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07142857142857142\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T14:00:39.833632Z",
     "start_time": "2024-09-24T17:52:10.347302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "differences = big_df['real_output'] != big_df['top_reconstructed_query_0.2_result']\n",
    "print(differences.sum()/len(differences))"
   ],
   "id": "5745d3c81c71470c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35714285714285715\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "91d05f29c1cc0691",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T14:15:43.802348Z",
     "start_time": "2024-09-25T14:15:43.783797Z"
    }
   },
   "cell_type": "code",
   "source": [
    "differences = big_df['real_output'] != big_df['bottom_reconstructed_instruction_0.2_result']\n",
    "print(differences.sum()/len(differences))"
   ],
   "id": "1ba31c43152ff3f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.030612244897959183\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T14:00:39.835534Z",
     "start_time": "2024-09-24T17:53:26.297777Z"
    }
   },
   "cell_type": "code",
   "source": [
    "differences = big_df['real_output'] != big_df['top_reconstructed_instruction_0.2_result']\n",
    "print(differences.sum()/len(differences))"
   ],
   "id": "9038b6db8146f6ea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T14:00:39.837522Z",
     "start_time": "2024-09-24T17:53:33.076169Z"
    }
   },
   "cell_type": "code",
   "source": "print(big_df['instruction_weight'].mean())",
   "id": "39d5e3fea00d7c55",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8787098084681545\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T14:00:39.838216Z",
     "start_time": "2024-09-24T17:53:34.665415Z"
    }
   },
   "cell_type": "code",
   "source": "print(big_df['query_weight'].mean())",
   "id": "6921c49d60e64cba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12129019153184557\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T14:15:49.186337Z",
     "start_time": "2024-09-25T14:15:49.178249Z"
    }
   },
   "cell_type": "code",
   "source": "print(big_df['exec_time'].mean())",
   "id": "b4dbeae654d5b86b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.86105881661785\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T14:15:59.968823Z",
     "start_time": "2024-09-25T14:15:59.964244Z"
    }
   },
   "cell_type": "code",
   "source": "print(big_df['input_cost'].mean())",
   "id": "c23afaaa0cc2bfb1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1426.1836734693877\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T14:16:01.699944Z",
     "start_time": "2024-09-25T14:16:01.691636Z"
    }
   },
   "cell_type": "code",
   "source": "print(big_df['output_cost'].mean())\n",
   "id": "a2e64a60b0a9055f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154.48979591836735\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T14:16:03.317001Z",
     "start_time": "2024-09-25T14:16:03.312234Z"
    }
   },
   "cell_type": "code",
   "source": "print(big_df['total_cost'].mean())\n",
   "id": "1c6233caab1f6d41",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1580.6734693877552\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T14:58:36.979270Z",
     "start_time": "2024-10-04T14:58:36.734194Z"
    }
   },
   "cell_type": "code",
   "source": "import numpy as np",
   "id": "ecc7b37c0f68e86a",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T14:58:45.836481Z",
     "start_time": "2024-10-04T14:58:45.809765Z"
    }
   },
   "cell_type": "code",
   "source": "x = np.array([[7.1, 7.1, 7.2], [8.3, 9.4, 10.5]])",
   "id": "4d01eeddc180dd41",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8863d12bf05db862"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T14:58:56.256430Z",
     "start_time": "2024-10-04T14:58:52.267031Z"
    }
   },
   "cell_type": "code",
   "source": "from scipy import stats",
   "id": "8da880475765a1d",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T14:59:03.180112Z",
     "start_time": "2024-10-04T14:59:03.106298Z"
    }
   },
   "cell_type": "code",
   "source": "res = stats.spearmanr(x)",
   "id": "dc34dfbe09d8fd0e",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T15:00:24.896633Z",
     "start_time": "2024-10-04T15:00:24.842852Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = np.array([7.1, 7.1, 7.2])\n",
    "y = np.array([8.3, 9.4, 10.5])\n",
    "res = stats.spearmanr(x,y)\n",
    "\n",
    "print(res)"
   ],
   "id": "442b6be160eeaf6a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SignificanceResult(statistic=0.8660254037844387, pvalue=0.3333333333333332)\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T15:09:14.800429Z",
     "start_time": "2024-10-04T15:09:14.720279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# Create a 2D array with sample data\n",
    "# Let's assume each row is an observation and each column is a different variable\n",
    "# data = np.array([\n",
    "#     [1, 2, 3.5],\n",
    "#     [2, 3, 2.5],\n",
    "# \n",
    "# ])\n",
    "data = np.array([\n",
    "    [1, 2, 3, 4, 5],     # Variable 1\n",
    "    [2, 3, 2, 1, 0],     # Variable 2\n",
    "    [3.5, 2.5, 0.5, 1.5, 3.0]  # Variable 3\n",
    "]).T\n",
    "# Calculate the Spearman correlation coefficient and p-value\n",
    "correlation, p_value = spearmanr(data)\n",
    "\n",
    "print(\"Spearman correlation coefficient matrix:\\n\", correlation)\n",
    "print(\"P-value matrix:\\n\", p_value)\n"
   ],
   "id": "5df415e16c5b805",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation coefficient matrix:\n",
      " [[ 1.         -0.82078268 -0.3       ]\n",
      " [-0.82078268  1.         -0.10259784]\n",
      " [-0.3        -0.10259784  1.        ]]\n",
      "P-value matrix:\n",
      " [[1.40426542e-24 8.85870053e-02 6.23837665e-01]\n",
      " [8.85870053e-02 0.00000000e+00 8.69597921e-01]\n",
      " [6.23837665e-01 8.69597921e-01 1.40426542e-24]]\n"
     ]
    }
   ],
   "execution_count": 48
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
