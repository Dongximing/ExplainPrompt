{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-20T17:46:50.675038Z",
     "start_time": "2024-09-20T17:46:49.917159Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def load_and_combine_pkl_files(directory_path):\n",
    "    # List to hold all the dataframes\n",
    "    dataframes = []\n",
    "\n",
    "    # Loop through all the files in the specified directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith('perturbed_inferenced_df.pkl'):\n",
    "            # Construct full file path\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            # Load the dataframe from a pkl file\n",
    "            df = pd.read_pickle(file_path)\n",
    "            # Append the dataframe to the list\n",
    "            dataframes.append(df)\n",
    "\n",
    "    # Concatenate all dataframes into one big dataframe\n",
    "    big_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    return big_df\n",
    "\n",
    "\n",
    "# Usage\n",
    "directory_path = '/Users/ximing/Desktop/Explainprompt'\n",
    "big_df = load_and_combine_pkl_files(directory_path)\n",
    "print(big_df)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                prompt real_output  \\\n",
      "0    maintains your sympathy for this otherwise cha...  ^POSITIVE^   \n",
      "1    all that memorable , but as downtown saturday ...  ^NEGATIVE^   \n",
      "2    there 's lots of cool stuff packed into espn '...  ^POSITIVE^   \n",
      "3    that this vapid vehicle is downright doltish a...  ^NEGATIVE^   \n",
      "4    a laughable -- or rather , unlaughable -- excu...  ^NEGATIVE^   \n",
      "..                                                 ...         ...   \n",
      "322  suffers from too much norma rae and not enough...  ^NEGATIVE^   \n",
      "323  offering next to little insight into its intri...  ^NEGATIVE^   \n",
      "324  a smart , provocative drama that does the near...  ^POSITIVE^   \n",
      "325  what passes for sex in the movies look like ch...  ^NEGATIVE^   \n",
      "326  gloriously flippant as lock , stock and two sm...  ^POSITIVE^   \n",
      "\n",
      "                                           token_level  \\\n",
      "0    {'tokens': [{'token': 'maint', 'type': 'input'...   \n",
      "1    {'tokens': [{'token': 'all', 'type': 'input', ...   \n",
      "2    {'tokens': [{'token': 'there', 'type': 'input'...   \n",
      "3    {'tokens': [{'token': 'that', 'type': 'input',...   \n",
      "4    {'tokens': [{'token': 'a', 'type': 'input', 'v...   \n",
      "..                                                 ...   \n",
      "322  {'tokens': [{'token': 's', 'type': 'input', 'v...   \n",
      "323  {'tokens': [{'token': 'off', 'type': 'input', ...   \n",
      "324  {'tokens': [{'token': 'a', 'type': 'input', 'v...   \n",
      "325  {'tokens': [{'token': 'what', 'type': 'input',...   \n",
      "326  {'tokens': [{'token': 'gl', 'type': 'input', '...   \n",
      "\n",
      "                                            word_level  label  \\\n",
      "0    {'tokens': [{'token': 'maintains', 'type': 'in...      1   \n",
      "1    {'tokens': [{'token': 'all', 'type': 'input', ...      1   \n",
      "2    {'tokens': [{'token': 'there', 'type': 'input'...      1   \n",
      "3    {'tokens': [{'token': 'that', 'type': 'input',...      0   \n",
      "4    {'tokens': [{'token': 'a', 'type': 'input', 'v...      0   \n",
      "..                                                 ...    ...   \n",
      "322  {'tokens': [{'token': 'suffers', 'type': 'inpu...      0   \n",
      "323  {'tokens': [{'token': 'offering', 'type': 'inp...      0   \n",
      "324  {'tokens': [{'token': 'a', 'type': 'input', 'v...      1   \n",
      "325  {'tokens': [{'token': 'what', 'type': 'input',...      0   \n",
      "326  {'tokens': [{'token': 'gloriously', 'type': 'i...      1   \n",
      "\n",
      "                                       component_level  \\\n",
      "0    ({'instruction': 0.521194192168358, 'query': 0...   \n",
      "1    ({'instruction': 0.7605099007025101, 'query': ...   \n",
      "2    ({'instruction': 0.8546850299919869, 'query': ...   \n",
      "3    ({'instruction': 0.9973476862448201, 'query': ...   \n",
      "4    ({'instruction': 0.8286308795575019, 'query': ...   \n",
      "..                                                 ...   \n",
      "322  ({'instruction': 0.9327413763085345, 'query': ...   \n",
      "323  ({'instruction': 0.6387966690564164, 'query': ...   \n",
      "324  ({'instruction': 0.8619142681642683, 'query': ...   \n",
      "325  ({'instruction': 0.9493110647181623, 'query': ...   \n",
      "326  ({'instruction': 0.6467651380864458, 'query': ...   \n",
      "\n",
      "                                           instruction  \\\n",
      "0    Analyze the sentiment of the previous sentence...   \n",
      "1    Analyze the sentiment of the previous sentence...   \n",
      "2    Analyze the sentiment of the previous sentence...   \n",
      "3    Analyze the sentiment of the previous sentence...   \n",
      "4    Analyze the sentiment of the previous sentence...   \n",
      "..                                                 ...   \n",
      "322  Analyze the sentiment of the previous sentence...   \n",
      "323  Analyze the sentiment of the previous sentence...   \n",
      "324  Analyze the sentiment of the previous sentence...   \n",
      "325  Analyze the sentiment of the previous sentence...   \n",
      "326  Analyze the sentiment of the previous sentence...   \n",
      "\n",
      "                                                 query  \\\n",
      "0    maintains your sympathy for this otherwise cha...   \n",
      "1    all that memorable , but as downtown saturday ...   \n",
      "2    there 's lots of cool stuff packed into espn '...   \n",
      "3    that this vapid vehicle is downright doltish a...   \n",
      "4    a laughable -- or rather , unlaughable -- excu...   \n",
      "..                                                 ...   \n",
      "322  suffers from too much norma rae and not enough...   \n",
      "323  offering next to little insight into its intri...   \n",
      "324  a smart , provocative drama that does the near...   \n",
      "325  what passes for sex in the movies look like ch...   \n",
      "326  gloriously flippant as lock , stock and two sm...   \n",
      "\n",
      "                                       component_range  instruction_weight  \\\n",
      "0    {'instruction': [8, 9, 10, 11, 12, 13, 14, 15,...            0.521194   \n",
      "1    {'instruction': [10, 11, 12, 13, 14, 15, 16, 1...            0.760510   \n",
      "2    {'instruction': [13, 14, 15, 16, 17, 18, 19, 2...            0.854685   \n",
      "3    {'instruction': [9, 10, 11, 12, 13, 14, 15, 16...            0.997348   \n",
      "4    {'instruction': [12, 13, 14, 15, 16, 17, 18, 1...            0.828631   \n",
      "..                                                 ...                 ...   \n",
      "322  {'instruction': [11, 12, 13, 14, 15, 16, 17, 1...            0.932741   \n",
      "323  {'instruction': [9, 10, 11, 12, 13, 14, 15, 16...            0.638797   \n",
      "324  {'instruction': [10, 11, 12, 13, 14, 15, 16, 1...            0.861914   \n",
      "325  {'instruction': [11, 12, 13, 14, 15, 16, 17, 1...            0.949311   \n",
      "326  {'instruction': [10, 11, 12, 13, 14, 15, 16, 1...            0.646765   \n",
      "\n",
      "     ...                       query_token_top_0.2_peturbed  \\\n",
      "0    ...  [{'token': 'shan', 'type': 'input', 'value': 0...   \n",
      "1    ...  [{'token': 'all', 'type': 'input', 'value': 0....   \n",
      "2    ...  [{'token': 'there', 'type': 'input', 'value': ...   \n",
      "3    ...  [{'token': 'that', 'type': 'input', 'value': 0...   \n",
      "4    ...  [{'token': 'a', 'type': 'input', 'value': 0.00...   \n",
      "..   ...                                                ...   \n",
      "322  ...  [{'token': 'Juno', 'type': 'input', 'value': 0...   \n",
      "323  ...  [{'token': 'Passiontide', 'type': 'input', 'va...   \n",
      "324  ...  [{'token': 'a', 'type': 'input', 'value': 0.00...   \n",
      "325  ...  [{'token': 'what', 'type': 'input', 'value': 0...   \n",
      "326  ...  [{'token': 'excommunicate', 'type': 'input', '...   \n",
      "\n",
      "                       query_token_bottom_0.2_peturbed  \\\n",
      "0    [{'token': 'maintains', 'type': 'input', 'valu...   \n",
      "1    [{'token': 'all', 'type': 'input', 'value': 0....   \n",
      "2    [{'token': 'there', 'type': 'input', 'value': ...   \n",
      "3    [{'token': 'that', 'type': 'input', 'value': 0...   \n",
      "4    [{'token': 'relational', 'type': 'input', 'val...   \n",
      "..                                                 ...   \n",
      "322  [{'token': 'suffers', 'type': 'input', 'value'...   \n",
      "323  [{'token': 'offering', 'type': 'input', 'value...   \n",
      "324  [{'token': 'annualist', 'type': 'input', 'valu...   \n",
      "325  [{'token': 'what', 'type': 'input', 'value': 0...   \n",
      "326  [{'token': 'gloriously', 'type': 'input', 'val...   \n",
      "\n",
      "                     top_reconstructed_instruction_0.2  \\\n",
      "0    maintains your sympathy for this otherwise cha...   \n",
      "1    all that memorable , but as downtown saturday ...   \n",
      "2    there 's lots of cool stuff packed into espn '...   \n",
      "3    that this vapid vehicle is downright doltish a...   \n",
      "4    a laughable -- or rather , unlaughable -- excu...   \n",
      "..                                                 ...   \n",
      "322  suffers from too much norma rae and not enough...   \n",
      "323  offering next to little insight into its intri...   \n",
      "324  a smart , provocative drama that does the near...   \n",
      "325  what passes for sex in the movies look like ch...   \n",
      "326  gloriously flippant as lock , stock and two sm...   \n",
      "\n",
      "                           top_reconstructed_query_0.2  \\\n",
      "0    shan your sympathy for this otherwise challeng...   \n",
      "1    all that memorable , but as downtown saturday ...   \n",
      "2    there 's lots of supercritical stuff packed in...   \n",
      "3    that this vapid vehicle is downright tritozooi...   \n",
      "4    a rhabdomancy -- or rather , unlaughable -- fo...   \n",
      "..                                                 ...   \n",
      "322  Juno from too much norma rae and not enough pr...   \n",
      "323  Passiontide next to little insight into its in...   \n",
      "324  a smart , provocative ratlike that boozer the ...   \n",
      "325  what passes for sex in the movies look like sa...   \n",
      "326  excommunicate flippant as lock , Larvalia and ...   \n",
      "\n",
      "                  bottom_reconstructed_instruction_0.2  \\\n",
      "0    maintains your sympathy for this otherwise cha...   \n",
      "1    all that memorable , but as downtown saturday ...   \n",
      "2    there 's lots of cool stuff packed into espn '...   \n",
      "3    that this vapid vehicle is downright doltish a...   \n",
      "4    a laughable -- or rather , unlaughable -- excu...   \n",
      "..                                                 ...   \n",
      "322  suffers from too much norma rae and not enough...   \n",
      "323  offering next to little insight into its intri...   \n",
      "324  a smart , provocative drama that does the near...   \n",
      "325  what passes for sex in the movies look like ch...   \n",
      "326  gloriously flippant as lock , stock and two sm...   \n",
      "\n",
      "                        bottom_reconstructed_query_0.2  \\\n",
      "0    maintains astragal sympathy for this otherwise...   \n",
      "1    all dressage subfossil , but as downtown satur...   \n",
      "2    there 's lots of cool Lutetian packed pipy esp...   \n",
      "3    that this vapid windily is downright doltish a...   \n",
      "4    relational laughable -- isomorph rather , unla...   \n",
      "..                                                 ...   \n",
      "322  suffers from too much norma rae spiraled not e...   \n",
      "323  offering next to little grottoed into its intr...   \n",
      "324  annualist smart , provocative drama upcatch do...   \n",
      "325  what passes for carburet in the cuittikin look...   \n",
      "326  gloriously thermopalpation as lock , stock and...   \n",
      "\n",
      "              top_reconstructed_instruction_0.2_result  \\\n",
      "0    I'm sorry, I cannot provide a response to that...   \n",
      "1    I'm sorry, I'm not sure what you mean by \"agna...   \n",
      "2                                                    ^   \n",
      "3                                           outquibble   \n",
      "4    I'm sorry, I do not understand the response op...   \n",
      "..                                                 ...   \n",
      "322                                            desirer   \n",
      "323                                          POSITIVE^   \n",
      "324  I'm sorry, I cannot provide a response to your...   \n",
      "325  I'm sorry, but I cannot provide a response usi...   \n",
      "326                                       Drepanididae   \n",
      "\n",
      "    top_reconstructed_query_0.2_result  \\\n",
      "0                           ^POSITIVE^   \n",
      "1                           ^POSITIVE^   \n",
      "2                           ^POSITIVE^   \n",
      "3                           ^NEGATIVE^   \n",
      "4                           ^NEGATIVE^   \n",
      "..                                 ...   \n",
      "322                         ^NEGATIVE^   \n",
      "323                         ^NEGATIVE^   \n",
      "324                         ^NEGATIVE^   \n",
      "325                         ^NEGATIVE^   \n",
      "326                         ^NEGATIVE^   \n",
      "\n",
      "    bottom_reconstructed_instruction_0.2_result  \\\n",
      "0                                    ^POSITIVE^   \n",
      "1                                    ^NEGATIVE^   \n",
      "2                                    ^POSITIVE^   \n",
      "3                                    ^NEGATIVE^   \n",
      "4                                    ^NEGATIVE^   \n",
      "..                                          ...   \n",
      "322                                  ^NEGATIVE^   \n",
      "323                                  ^NEGATIVE^   \n",
      "324                                  ^POSITIVE^   \n",
      "325                                  ^NEGATIVE^   \n",
      "326                                  ^POSITIVE^   \n",
      "\n",
      "    bottom_reconstructed_query_0.2_result  \n",
      "0                              ^POSITIVE^  \n",
      "1                              ^NEGATIVE^  \n",
      "2                              ^POSITIVE^  \n",
      "3                              ^NEGATIVE^  \n",
      "4                              ^NEGATIVE^  \n",
      "..                                    ...  \n",
      "322                            ^NEGATIVE^  \n",
      "323                            ^POSITIVE^  \n",
      "324                            ^POSITIVE^  \n",
      "325                            ^NEGATIVE^  \n",
      "326                            ^POSITIVE^  \n",
      "\n",
      "[327 rows x 25 columns]\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T17:46:54.537191Z",
     "start_time": "2024-09-20T17:46:54.533671Z"
    }
   },
   "cell_type": "code",
   "source": "print(big_df.columns)",
   "id": "245a45e8399d08b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['prompt', 'real_output', 'token_level', 'word_level', 'label',\n",
      "       'component_level', 'instruction', 'query', 'component_range',\n",
      "       'instruction_weight', 'query_weight', 'instructions_tokens',\n",
      "       'query_tokens', 'instruction_token_top_0.2_peturbed',\n",
      "       'instruction_token_bottom_0.2_peturbed', 'query_token_top_0.2_peturbed',\n",
      "       'query_token_bottom_0.2_peturbed', 'top_reconstructed_instruction_0.2',\n",
      "       'top_reconstructed_query_0.2', 'bottom_reconstructed_instruction_0.2',\n",
      "       'bottom_reconstructed_query_0.2',\n",
      "       'top_reconstructed_instruction_0.2_result',\n",
      "       'top_reconstructed_query_0.2_result',\n",
      "       'bottom_reconstructed_instruction_0.2_result',\n",
      "       'bottom_reconstructed_query_0.2_result'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T17:47:00.513354Z",
     "start_time": "2024-09-20T17:47:00.506806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "differences = big_df['real_output'] != big_df['bottom_reconstructed_query_0.2_result']\n",
    "print(differences.sum()/len(differences))"
   ],
   "id": "864ecdc676891e34",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07033639143730887\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T17:47:03.965677Z",
     "start_time": "2024-09-20T17:47:03.960441Z"
    }
   },
   "cell_type": "code",
   "source": [
    "differences = big_df['real_output'] != big_df['top_reconstructed_query_0.2_result']\n",
    "print(differences.sum()/len(differences))"
   ],
   "id": "5745d3c81c71470c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3363914373088685\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T17:47:06.583718Z",
     "start_time": "2024-09-20T17:47:06.577692Z"
    }
   },
   "cell_type": "code",
   "source": [
    "differences = big_df['real_output'] != big_df['bottom_reconstructed_instruction_0.2_result']\n",
    "print(differences.sum()/len(differences))"
   ],
   "id": "1ba31c43152ff3f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1529051987767584\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T17:47:11.514243Z",
     "start_time": "2024-09-20T17:47:11.509539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "differences = big_df['real_output'] != big_df['top_reconstructed_instruction_0.2_result']\n",
    "print(differences.sum()/len(differences))"
   ],
   "id": "9038b6db8146f6ea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9877675840978594\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T18:06:10.189986Z",
     "start_time": "2024-09-20T18:06:10.101274Z"
    }
   },
   "cell_type": "code",
   "source": "print(big_df['instruction_weight'].mean())",
   "id": "39d5e3fea00d7c55",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.796419031248912\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T18:06:36.219868Z",
     "start_time": "2024-09-20T18:06:36.188854Z"
    }
   },
   "cell_type": "code",
   "source": "print(big_df['query_weight'].mean())",
   "id": "6921c49d60e64cba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20105899439910707\n"
     ]
    }
   ],
   "execution_count": 22
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
