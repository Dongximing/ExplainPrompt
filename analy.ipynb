{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-23T13:44:54.968021Z",
     "start_time": "2024-09-23T13:44:54.081748Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def load_and_combine_pkl_files(directory_path):\n",
    "    # List to hold all the dataframes\n",
    "    dataframes = []\n",
    "\n",
    "    # Loop through all the files in the specified directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith('perturbed_inferenced_df.pkl'):\n",
    "            # Construct full file path\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            # Load the dataframe from a pkl file\n",
    "            df = pd.read_pickle(file_path)\n",
    "            # Append the dataframe to the list\n",
    "            dataframes.append(df)\n",
    "\n",
    "    # Concatenate all dataframes into one big dataframe\n",
    "    big_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    return big_df\n",
    "\n",
    "\n",
    "# Usage\n",
    "directory_path = '/Users/ximing/Desktop/Explainprompt'\n",
    "big_df = load_and_combine_pkl_files(directory_path)\n",
    "print(big_df)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 prompt real_output  \\\n",
      "0     recommended -- as visually bland as a dentist ...  ^NEGATIVE^   \n",
      "1     to winger fans who have missed her since 1995 ...  ^POSITIVE^   \n",
      "2     wow , so who knew charles dickens could be so ...  ^POSITIVE^   \n",
      "3     fresh to say about growing up catholic or , re...  ^POSITIVE^   \n",
      "4     used manhattan 's architecture in such a glori...  ^POSITIVE^   \n",
      "...                                                 ...         ...   \n",
      "1960  joan and philip 's repetitive arguments , sche...  ^NEGATIVE^   \n",
      "1961  had gone a tad less for grit and a lot more fo...  ^POSITIVE^   \n",
      "1962  highly entertaining , self-aggrandizing , poli...  ^NEGATIVE^   \n",
      "1963  a dark , quirky road movie that constantly def...  ^POSITIVE^   \n",
      "1964  in terms of the low-grade cheese standards on ...  ^NEGATIVE^   \n",
      "\n",
      "                                            token_level  \\\n",
      "0     {'tokens': [{'token': 'recommended', 'type': '...   \n",
      "1     {'tokens': [{'token': 'to', 'type': 'input', '...   \n",
      "2     {'tokens': [{'token': 'wow', 'type': 'input', ...   \n",
      "3     {'tokens': [{'token': 'fresh', 'type': 'input'...   \n",
      "4     {'tokens': [{'token': 'used', 'type': 'input',...   \n",
      "...                                                 ...   \n",
      "1960  {'tokens': [{'token': 'jo', 'type': 'input', '...   \n",
      "1961  {'tokens': [{'token': 'had', 'type': 'input', ...   \n",
      "1962  {'tokens': [{'token': 'high', 'type': 'input',...   \n",
      "1963  {'tokens': [{'token': 'a', 'type': 'input', 'v...   \n",
      "1964  {'tokens': [{'token': 'in', 'type': 'input', '...   \n",
      "\n",
      "                                             word_level  label  \\\n",
      "0     {'tokens': [{'token': 'recommended', 'type': '...      0   \n",
      "1     {'tokens': [{'token': 'to', 'type': 'input', '...      1   \n",
      "2     {'tokens': [{'token': 'wow', 'type': 'input', ...      1   \n",
      "3     {'tokens': [{'token': 'fresh', 'type': 'input'...      0   \n",
      "4     {'tokens': [{'token': 'used', 'type': 'input',...      1   \n",
      "...                                                 ...    ...   \n",
      "1960  {'tokens': [{'token': 'joan', 'type': 'input',...      0   \n",
      "1961  {'tokens': [{'token': 'had', 'type': 'input', ...      0   \n",
      "1962  {'tokens': [{'token': 'highly', 'type': 'input...      1   \n",
      "1963  {'tokens': [{'token': 'a', 'type': 'input', 'v...      1   \n",
      "1964  {'tokens': [{'token': 'in', 'type': 'input', '...      0   \n",
      "\n",
      "                                        component_level  \\\n",
      "0     ({'instruction': 0.6446144643240199, 'query': ...   \n",
      "1     ({'instruction': 0.5349158643242384, 'query': ...   \n",
      "2     ({'instruction': 0.48872836608976233, 'query':...   \n",
      "3     ({'instruction': 0.8260740891602995, 'query': ...   \n",
      "4     ({'instruction': 0.574440055205557, 'query': 0...   \n",
      "...                                                 ...   \n",
      "1960  ({'instruction': 0.8191093783913279, 'query': ...   \n",
      "1961  ({'instruction': 0.6922049476867784, 'query': ...   \n",
      "1962  ({'instruction': 0.6212751040838753, 'query': ...   \n",
      "1963  ({'instruction': 0.8554989248018277, 'query': ...   \n",
      "1964  ({'instruction': 0.7493804826469873, 'query': ...   \n",
      "\n",
      "                                            instruction  \\\n",
      "0     Analyze the sentiment of the previous sentence...   \n",
      "1     Analyze the sentiment of the previous sentence...   \n",
      "2     Analyze the sentiment of the previous sentence...   \n",
      "3     Analyze the sentiment of the previous sentence...   \n",
      "4     Analyze the sentiment of the previous sentence...   \n",
      "...                                                 ...   \n",
      "1960  Analyze the sentiment of the previous sentence...   \n",
      "1961  Analyze the sentiment of the previous sentence...   \n",
      "1962  Analyze the sentiment of the previous sentence...   \n",
      "1963  Analyze the sentiment of the previous sentence...   \n",
      "1964  Analyze the sentiment of the previous sentence...   \n",
      "\n",
      "                                                  query  \\\n",
      "0     recommended -- as visually bland as a dentist ...   \n",
      "1     to winger fans who have missed her since 1995 ...   \n",
      "2     wow , so who knew charles dickens could be so ...   \n",
      "3     fresh to say about growing up catholic or , re...   \n",
      "4     used manhattan 's architecture in such a glori...   \n",
      "...                                                 ...   \n",
      "1960  joan and philip 's repetitive arguments , sche...   \n",
      "1961  had gone a tad less for grit and a lot more fo...   \n",
      "1962  highly entertaining , self-aggrandizing , poli...   \n",
      "1963  a dark , quirky road movie that constantly def...   \n",
      "1964  in terms of the low-grade cheese standards on ...   \n",
      "\n",
      "                                        component_range  instruction_weight  \\\n",
      "0     {'instruction': [11, 12, 13, 14, 15, 16, 17, 1...            0.644614   \n",
      "1     {'instruction': [12, 13, 14, 15, 16, 17, 18, 1...            0.534916   \n",
      "2     {'instruction': [12, 13, 14, 15, 16, 17, 18, 1...            0.488728   \n",
      "3     {'instruction': [12, 13, 14, 15, 16, 17, 18, 1...            0.826074   \n",
      "4     {'instruction': [10, 11, 12, 13, 14, 15, 16, 1...            0.574440   \n",
      "...                                                 ...                 ...   \n",
      "1960  {'instruction': [10, 11, 12, 13, 14, 15, 16, 1...            0.819109   \n",
      "1961  {'instruction': [13, 14, 15, 16, 17, 18, 19, 2...            0.692205   \n",
      "1962  {'instruction': [7, 8, 9, 10, 11, 12, 13, 14, ...            0.621275   \n",
      "1963  {'instruction': [11, 12, 13, 14, 15, 16, 17, 1...            0.855499   \n",
      "1964  {'instruction': [11, 12, 13, 14, 15, 16, 17, 1...            0.749380   \n",
      "\n",
      "      ...                       query_token_top_0.2_peturbed  \\\n",
      "0     ...  [{'token': 'recommended', 'type': 'input', 'va...   \n",
      "1     ...  [{'token': 'Sclav', 'type': 'input', 'value': ...   \n",
      "2     ...  [{'token': 'wow', 'type': 'input', 'value': 0....   \n",
      "3     ...  [{'token': 'supramechanical', 'type': 'input',...   \n",
      "4     ...  [{'token': 'saronide', 'type': 'input', 'value...   \n",
      "...   ...                                                ...   \n",
      "1960  ...  [{'token': 'joan', 'type': 'input', 'value': 0...   \n",
      "1961  ...  [{'token': 'had', 'type': 'input', 'value': 0....   \n",
      "1962  ...  [{'token': 'highly', 'type': 'input', 'value':...   \n",
      "1963  ...  [{'token': 'a', 'type': 'input', 'value': 0.00...   \n",
      "1964  ...  [{'token': 'in', 'type': 'input', 'value': 0.0...   \n",
      "\n",
      "                        query_token_bottom_0.2_peturbed  \\\n",
      "0     [{'token': 'khula', 'type': 'input', 'value': ...   \n",
      "1     [{'token': 'to', 'type': 'input', 'value': 0.1...   \n",
      "2     [{'token': 'backwards', 'type': 'input', 'valu...   \n",
      "3     [{'token': 'fresh', 'type': 'input', 'value': ...   \n",
      "4     [{'token': 'used', 'type': 'input', 'value': 0...   \n",
      "...                                                 ...   \n",
      "1960  [{'token': 'joan', 'type': 'input', 'value': 0...   \n",
      "1961  [{'token': 'had', 'type': 'input', 'value': 0....   \n",
      "1962  [{'token': 'highly', 'type': 'input', 'value':...   \n",
      "1963  [{'token': 'cylindroid', 'type': 'input', 'val...   \n",
      "1964  [{'token': 'in', 'type': 'input', 'value': 0.0...   \n",
      "\n",
      "                      top_reconstructed_instruction_0.2  \\\n",
      "0     recommended -- as visually bland as a dentist ...   \n",
      "1     to winger fans who have missed her since 1995 ...   \n",
      "2     wow , so who knew charles dickens could be so ...   \n",
      "3     fresh to say about growing up catholic or , re...   \n",
      "4     used manhattan 's architecture in such a glori...   \n",
      "...                                                 ...   \n",
      "1960  joan and philip 's repetitive arguments , sche...   \n",
      "1961  had gone a tad less for grit and a lot more fo...   \n",
      "1962  highly entertaining , self-aggrandizing , poli...   \n",
      "1963  a dark , quirky road movie that constantly def...   \n",
      "1964  in terms of the low-grade cheese standards on ...   \n",
      "\n",
      "                            top_reconstructed_query_0.2  \\\n",
      "0     recommended -- as visually unsupreme Hexateuch...   \n",
      "1     Sclav winger fans superregulation have missed ...   \n",
      "2     wow , so who trichophoric charles dickens coul...   \n",
      "3     supramechanical to say Ibycus growing up catho...   \n",
      "4     saronide manhattan 's architecture in such a u...   \n",
      "...                                                 ...   \n",
      "1960  joan and philip 's aboma arguments , schemes a...   \n",
      "1961  had gone a tad less for pyrheliometer frivolit...   \n",
      "1962  highly entertaining , underlinen , politically...   \n",
      "1963  a dark , quirky road movie that constantly car...   \n",
      "1964  in terms of the Dogrib cheese standards on whi...   \n",
      "\n",
      "                   bottom_reconstructed_instruction_0.2  \\\n",
      "0     recommended -- as visually bland as a dentist ...   \n",
      "1     to winger fans who have missed her since 1995 ...   \n",
      "2     wow , so who knew charles dickens could be so ...   \n",
      "3     fresh to say about growing up catholic or , re...   \n",
      "4     used manhattan 's architecture in such a glori...   \n",
      "...                                                 ...   \n",
      "1960  joan and philip 's repetitive arguments , sche...   \n",
      "1961  had gone a tad less for grit and a lot more fo...   \n",
      "1962  highly entertaining , self-aggrandizing , poli...   \n",
      "1963  a dark , quirky road movie that constantly def...   \n",
      "1964  in terms of the low-grade cheese standards on ...   \n",
      "\n",
      "                         bottom_reconstructed_query_0.2  \\\n",
      "0     khula -- as visually bland as ecole dentist 's...   \n",
      "1     to metaphysic fans who towner missed her since...   \n",
      "2     backwards , so who knew charles dickens could ...   \n",
      "3     fresh to say about shamateur philocomal cathol...   \n",
      "4     used manhattan 's architecture revolving such ...   \n",
      "...                                                 ...   \n",
      "1960  joan and philip 's repetitive arguments , chri...   \n",
      "1961  had gone a tad Beckie for grit and a lot views...   \n",
      "1962  highly mariticidal , self-aggrandizing , polit...   \n",
      "1963  cylindroid leucite , quirky road movie that co...   \n",
      "1964  in ventriloquially of the low-grade ephoral st...   \n",
      "\n",
      "               top_reconstructed_instruction_0.2_result  \\\n",
      "0                                              downfold   \n",
      "1     The sentiment of the previous sentence is nost...   \n",
      "2     The sentiment of the previous sentence is posi...   \n",
      "3                                                 reree   \n",
      "4                                                moving   \n",
      "...                                                 ...   \n",
      "1960                                         ^POSITIVE^   \n",
      "1961                                         ^NEGATIVE^   \n",
      "1962                                         ^POSITIVE^   \n",
      "1963  The sentiment of the previous sentence is posi...   \n",
      "1964                                         ^POSITIVE^   \n",
      "\n",
      "     top_reconstructed_query_0.2_result  \\\n",
      "0                            ^NEGATIVE^   \n",
      "1                            ^NEGATIVE^   \n",
      "2                            ^POSITIVE^   \n",
      "3                            ^POSITIVE^   \n",
      "4                            ^NEGATIVE^   \n",
      "...                                 ...   \n",
      "1960                          NEGATIVE^   \n",
      "1961                         ^POSITIVE^   \n",
      "1962                         ^POSITIVE^   \n",
      "1963                         ^NEGATIVE^   \n",
      "1964                         ^POSITIVE^   \n",
      "\n",
      "     bottom_reconstructed_instruction_0.2_result  \\\n",
      "0                                     ^NEGATIVE^   \n",
      "1                                     ^POSITIVE^   \n",
      "2                                     ^POSITIVE^   \n",
      "3                                     ^POSITIVE^   \n",
      "4                                     ^POSITIVE^   \n",
      "...                                          ...   \n",
      "1960                                  ^NEGATIVE^   \n",
      "1961                                  ^POSITIVE^   \n",
      "1962                                  ^NEGATIVE^   \n",
      "1963                                  ^POSITIVE^   \n",
      "1964                                  ^NEGATIVE^   \n",
      "\n",
      "     bottom_reconstructed_query_0.2_result  \n",
      "0                               ^NEGATIVE^  \n",
      "1                               ^POSITIVE^  \n",
      "2                               ^POSITIVE^  \n",
      "3                               ^POSITIVE^  \n",
      "4                               ^POSITIVE^  \n",
      "...                                    ...  \n",
      "1960                             NEGATIVE^  \n",
      "1961                            ^NEGATIVE^  \n",
      "1962                            ^NEGATIVE^  \n",
      "1963                            ^POSITIVE^  \n",
      "1964                            ^NEGATIVE^  \n",
      "\n",
      "[1965 rows x 25 columns]\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T13:45:01.171494Z",
     "start_time": "2024-09-23T13:45:01.148375Z"
    }
   },
   "cell_type": "code",
   "source": "print(big_df.columns)",
   "id": "245a45e8399d08b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['prompt', 'real_output', 'token_level', 'word_level', 'label',\n",
      "       'component_level', 'instruction', 'query', 'component_range',\n",
      "       'instruction_weight', 'query_weight', 'instructions_tokens',\n",
      "       'query_tokens', 'instruction_token_top_0.2_peturbed',\n",
      "       'instruction_token_bottom_0.2_peturbed', 'query_token_top_0.2_peturbed',\n",
      "       'query_token_bottom_0.2_peturbed', 'top_reconstructed_instruction_0.2',\n",
      "       'top_reconstructed_query_0.2', 'bottom_reconstructed_instruction_0.2',\n",
      "       'bottom_reconstructed_query_0.2',\n",
      "       'top_reconstructed_instruction_0.2_result',\n",
      "       'top_reconstructed_query_0.2_result',\n",
      "       'bottom_reconstructed_instruction_0.2_result',\n",
      "       'bottom_reconstructed_query_0.2_result'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T13:45:05.209112Z",
     "start_time": "2024-09-23T13:45:05.169586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "differences = big_df['real_output'] != big_df['bottom_reconstructed_query_0.2_result']\n",
    "print(differences.sum()/len(differences))"
   ],
   "id": "864ecdc676891e34",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0717557251908397\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T13:45:10.143739Z",
     "start_time": "2024-09-23T13:45:10.130664Z"
    }
   },
   "cell_type": "code",
   "source": [
    "differences = big_df['real_output'] != big_df['top_reconstructed_query_0.2_result']\n",
    "print(differences.sum()/len(differences))"
   ],
   "id": "5745d3c81c71470c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37251908396946565\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T13:45:13.903306Z",
     "start_time": "2024-09-23T13:45:13.858616Z"
    }
   },
   "cell_type": "code",
   "source": [
    "differences = big_df['real_output'] != big_df['bottom_reconstructed_instruction_0.2_result']\n",
    "print(differences.sum()/len(differences))"
   ],
   "id": "1ba31c43152ff3f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12111959287531807\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T13:45:18.611551Z",
     "start_time": "2024-09-23T13:45:18.605387Z"
    }
   },
   "cell_type": "code",
   "source": [
    "differences = big_df['real_output'] != big_df['top_reconstructed_instruction_0.2_result']\n",
    "print(differences.sum()/len(differences))"
   ],
   "id": "9038b6db8146f6ea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9938931297709923\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T13:45:23.622663Z",
     "start_time": "2024-09-23T13:45:23.617626Z"
    }
   },
   "cell_type": "code",
   "source": "print(big_df['instruction_weight'].mean())",
   "id": "39d5e3fea00d7c55",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7873167049738102\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T13:45:26.340594Z",
     "start_time": "2024-09-23T13:45:26.319856Z"
    }
   },
   "cell_type": "code",
   "source": "print(big_df['query_weight'].mean())",
   "id": "6921c49d60e64cba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2114628815611635\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b4dbeae654d5b86b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
